{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geocoding with Python\n",
    "\n",
    "In this tutorial we will explore a method for mapping locations from a list of place names using Python.\n",
    "\n",
    "The dataset used is from the [Italian Academies Project](italianacademies.org/), which is available for [download](https://doi.org/10.21250/iad1) via data.bl.uk. The XML records contained in the dataset include metadata for the Italian academies of the late Renaissance and early modern periods. These records contain tags that specify the names and locations of each academy. This is the data that we will extract and use to build our map.\n",
    "\n",
    "We will use two key Python libraries: [geopy](https://pypi.python.org/pypi/geopy) and [folium](https://pypi.python.org/pypi/folium). Geopy will be used to look up the coordinates of place names using [OpenStreetMap](https://www.openstreetmap.org/) data and folium will be used to display those coordinates on a [Leaflet](http://leafletjs.com/) map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This tutorial assumes that you already have [Python](https://www.python.org/) installed and have some familiarity with running Python scripts.\n",
    "\n",
    "With that in mind, we will start by installing the required software libraries via [PyPi](https://pypi.python.org/pypi). Open up a command-line interface and run the following:\n",
    "\n",
    "```\n",
    "pip install geopy folium requests tqdm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries\n",
    "\n",
    "With the required libraries installed we can now start writing our Python script. Using a text editor, create a new file and save it as `run.py`, then enter the following code to import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import time\n",
    "import requests\n",
    "import zipfile\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import xml.etree.ElementTree as ET\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare some common variables\n",
    "\n",
    "There are some common variables that will be used in various places throughout the tutorial. We will declare these below the imports for easier reference. The comments above each variable indicate their purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory to which we will download our dataset.\n",
    "DATA_DIR = '../data'\n",
    "\n",
    "# An HTTP header that we add to identify our application over a network.\n",
    "USER_AGENT = 'bl-digischol-notebooks'\n",
    "\n",
    "# The name of the dataset collection\n",
    "COLLECTION = 'iad'\n",
    "\n",
    "# The name of the dataset\n",
    "DATASET = 'iad-xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "We now need to download our dataset and extract the files is contains. The code block below will handle this programmatically. Copy the code into your Python script, save the file, then open up a command-line interface, navigate to the location of your script and run the following:\n",
    "\n",
    "```\n",
    "python run.py\n",
    "```\n",
    "\n",
    "Assuming the dataset does not already exist in the correct location it will be downloaded and the files extracted. For more details about how the process works, see [Downloading datasets with Python](downloading_datasets_with_python.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "    \n",
    "\n",
    "def download_dataset(collection, dataset, directory, user_agent):\n",
    "    url = 'https://data.bl.uk/{0}/{1}.zip'.format(collection, dataset)\n",
    "    download_fn = url.split('/')[-1]\n",
    "    download_path = os.path.join(directory, download_fn)\n",
    "    if not os.path.exists(download_path):\n",
    "        headers = {'User-agent': user_agent}\n",
    "        r = requests.get(url, stream=True, headers=headers)\n",
    "        total_length = int(r.headers.get('Content-Length'))\n",
    "        total_size = (total_length/1024) + 1\n",
    "        with open(download_path, 'wb') as f:\n",
    "            for chunk in tqdm.tqdm(r.iter_content(chunk_size=1024), \n",
    "                                   total=total_size, \n",
    "                                   desc='Downloading', \n",
    "                                   unit='kb',\n",
    "                                   unit_scale=True, \n",
    "                                   miniters=1, \n",
    "                                   leave=False): \n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "\n",
    "def extract_dataset(dataset, data_dir):\n",
    "    fn = '{}.zip'.format(dataset)\n",
    "    in_path = os.path.join(data_dir, fn)\n",
    "    with zipfile.ZipFile(in_path) as archive:\n",
    "        unextracted = [name for name in archive.namelist() \n",
    "                       if not os.path.exists(os.path.join(data_dir, name))]\n",
    "        if unextracted:\n",
    "            for i in tqdm.tqdm(range(len(unextracted)), \n",
    "                               desc='Extracting', \n",
    "                               unit='file', \n",
    "                               leave=False):\n",
    "                archive.extract(unextracted[i], path=data_dir)\n",
    "\n",
    "\n",
    "create_data_dir(DATA_DIR)\n",
    "download_dataset(COLLECTION, DATASET, DATA_DIR, USER_AGENT)\n",
    "extract_dataset(DATASET, DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract details of the academies\n",
    "\n",
    "With our libraries imported and dataset prepared we're now ready to begin extracting the location details for each academy from the XML records. To do this we will [ElementTree](https://docs.python.org/2/library/xml.etree.elementtree.html), which is an API for manipulating XML, implemented in the Python standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_academy_summaries(data_dir, dataset):\n",
    "    data = []\n",
    "    records_dir = '{0}/{1}/records/ItacAcademyItem'.format(data_dir, dataset)\n",
    "    for xml_file in os.listdir(records_dir):\n",
    "        path = os.path.join(records_dir, xml_file)\n",
    "        with open(path) as f:\n",
    "            tree = ET.parse(f)\n",
    "            root = tree.getroot()\n",
    "            city = root.find(\".//*/CityItalianName\").text\n",
    "            name = root.find(\".//Name\").text\n",
    "            academy = dict(name=name, city=city)\n",
    "            data.append(academy)\n",
    "    return data\n",
    "\n",
    "academies = get_academy_summaries(DATA_DIR, DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the place names into coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def get_markers(academies, user_agent):\n",
    "    geolocator = Nominatim(user_agent=user_agent)\n",
    "    locations = {}\n",
    "    markers = []\n",
    "    for academy in tqdm.tqdm(academies, desc='Locating', unit='file', leave=False):\n",
    "        city = academy['city']\n",
    "        name = academy['name']\n",
    "        \n",
    "        if not locations.get(city):\n",
    "            location = geolocator.geocode(city + ', Italy')\n",
    "            if not location:\n",
    "                continue\n",
    "                \n",
    "            coordinates = (location.latitude, location.longitude)\n",
    "            locations[city] = coordinates\n",
    "            \n",
    "            # Comply with usage policy of a maximum of 1 request per second                  \n",
    "            time.sleep(1)\n",
    "        \n",
    "        marker = dict(location=locations[city], popup=name)\n",
    "        markers.append(marker)\n",
    "    return markers\n",
    "    \n",
    "    \n",
    "markers = get_markers(academies, USER_AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_map():\n",
    "    italy_coords = (41.87, 12.56)\n",
    "    map = folium.Map(location=italy_coords, zoom_start=6)\n",
    "\n",
    "    marker_cluster = MarkerCluster().add_to(map)\n",
    "\n",
    "    for marker in markers:\n",
    "        folium.Marker(**marker).add_to(marker_cluster)\n",
    "\n",
    "    map.save(os.path.join(DATA_DIR, 'iad-academies.html'))\n",
    "\n",
    "    map\n",
    "\n",
    "build_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap up\n",
    "\n",
    "Wrapping it up...\n",
    "\n",
    "[Link](../data/iad-academies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
